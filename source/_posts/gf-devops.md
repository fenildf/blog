
数据采集包括了：

fluent, statsd, zabbix agent and plugin, logstash




![](media/14764146287786.jpg)



- 数据的采集

数据是多种多样的。包括了从日志中抽取的信息，也包括从接口或命令中获得信息。它们可能是关于资源可用，软件性能或是业务行为的，或者是系统中不同层面的组成部分（如应用服务，Linux基础服务器，数据库等）的状态数据。

采集的行为，包括了主动和被动的方式，后者又分为白盒（log parsers, log scanners, interface readers）和黑盒（probers, sniffers）。

最终以某种形式上报给服务器。它是一系列的被分组的连续、周期、有序的数据点集合。每个数据点由被测量后记录的数值，记录采集时间的时间戳和描述数据点的系列属性（如主机名，ip等）所组成。

- 指标的计算

我们指标中的数据点被按照固定时间间隔被分块，通过某种有意义的数学变换来概括和统计。包括了常见的

- 时间序列和存储

对流出的日志条目在时间轴上抽取，被计算的指标被以时间序列的形式被呈现，然后绘制二维图表，从而从趋势上快速发现问题所在。

- 仪表盘可视化


- 监控告警

主要用于对服务进行心跳检测、监控服务的各项指标，当某些指标异常或超过设定的阈值时进行短信、SMS、邮件的报警（实现 escalate! 危机告警升级）。

